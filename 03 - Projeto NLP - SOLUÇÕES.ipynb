{"cells":[{"cell_type":"markdown","metadata":{"id":"N8O5nHL3UPwR"},"source":["# Projeto de Processamento de Linguagem Natural\n","\n","Neste projeto de NLP, você tentará classificar as avaliações do Yelp em categorias de 1 ou 5 estrelas com base no conteúdo do texto nas avaliações. Utilizaremos os métodos de pipeline para tarefas mais complexas.\n","\n","Utilizaremos o [Yelp Review Data Set](https://www.kaggle.com/c/yelp-recsys-2013) do Kaggle.\n","\n","Cada observação neste conjunto de dados é uma revisão de um determinado negócio por um determinado usuário.\n","\n","A coluna \"stars\" é o número de estrelas (1 a 5) atribuídas pelo revisor à empresa.\n","\n","A coluna \"cool\" é o número de votos \"cool\" que esta avaliação recebeu de outros usuários do Yelp.\n","\n","Todas as resenhas começam com 0 votos \"cool\" e não há limite para quantos votos \"cool\" uma resenha pode receber. Em outras palavras, é uma classificação da avaliação em si, não uma classificação do negócio.\n","\n","As colunas \"useful\" e \"funny\" são semelhantes à coluna \"cool\"."]},{"cell_type":"markdown","metadata":{"id":"RJzwfKRtUPwS"},"source":["## Importações\n","**Importe os usual suspects :)**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"uQg0v4drUPwT"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"4QfsmE1LUPwU"},"source":["## Os dados\n","\n","**Leia o arquivo yelp.csv e defina-o como um dataframe chamado yelp.**"]},{"cell_type":"code","source":["# Esse trecho do código é obrigatório para quem estiver fazendo tudo pelo colab\n","# Caso você esteja utilizando o jupyter pode comentar/apagar\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","os.chdir(\"drive/My Drive/Colab Notebooks/IA/20_Natural_Language_Processing\")\n","os.listdir()"],"metadata":{"id":"7FgdIYU_V549"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"vC_gCx8tUPwU"},"outputs":[],"source":["yelp = pd.read_csv('yelp.csv')"]},{"cell_type":"markdown","metadata":{"id":"JEKvAU4zUPwV"},"source":["**Verifique os métodos head, info e describe no yelp.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iakrlpNUPwV"},"outputs":[],"source":["yelp.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9PtDbAxUPwX"},"outputs":[],"source":["yelp.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ov9giuLqUPwX"},"outputs":[],"source":["yelp.describe()"]},{"cell_type":"markdown","metadata":{"id":"dBqAXNjaUPwY"},"source":["**Crie uma nova coluna chamada \"text length\", que é o número de palavras na coluna de texto.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"oagKBXHzUPwY"},"outputs":[],"source":["yelp['text length'] = yelp['text'].apply(len)"]},{"cell_type":"markdown","metadata":{"id":"QkvEo2aEUPwY"},"source":["# EDA\n","\n","**Importe as bibliotecas de visualização de dados, caso ainda não o tenha feito.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"U3jA4BOyUPwZ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('white')\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"U61AFs6CUPwZ"},"source":["**Use o FacetGrid da biblioteca seaborn para criar uma grade de 5 histogramas do comprimento do texto com base na quantidade de estrelas recebidas. Consulte a documentação do seaborn para obter dicas sobre isso**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3hiD0q8UPwa"},"outputs":[],"source":["g = sns.FacetGrid(yelp,col='stars')\n","g.map(plt.hist,'text length')"]},{"cell_type":"markdown","metadata":{"id":"NmQ5BfBkUPwa"},"source":["**Crie um boxplot de tamanho de texto para cada categoria de estrela (quantidade de estrelas recebidas).**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2DvEPoe8UPwa"},"outputs":[],"source":["sns.boxplot(x='stars',y='text length',data=yelp,palette='rainbow')"]},{"cell_type":"markdown","metadata":{"id":"PW9pQNkKUPwa"},"source":["**Crie um countplot do número de ocorrências para cada tipo de classificação por estrelas.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hmwLgI7UPwb"},"outputs":[],"source":["sns.countplot(x='stars',data=yelp,palette='rainbow')"]},{"cell_type":"markdown","metadata":{"id":"5CTtbh7oUPwb"},"source":["**Use groupby para obter os valores médios das colunas numéricas, você deve ser capaz de criar este dataframe com a operação:**\n","\n","`stars = yelp.groupby('stars').mean()`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9NhPlWSUPwc"},"outputs":[],"source":["stars = yelp.groupby('stars').mean()\n","stars"]},{"cell_type":"markdown","metadata":{"id":"udKSta-MUPwc"},"source":["**Use o método corr() nesse dataframe groupby:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mt8TGDwIUPwc"},"outputs":[],"source":["stars.corr()"]},{"cell_type":"markdown","metadata":{"id":"qr4qwtldUPwc"},"source":["**Em seguida, use seaborn para criar um mapa de calor baseado nesse dataframe .corr():**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sp690SwdUPwc"},"outputs":[],"source":["sns.heatmap(stars.corr(),cmap='coolwarm',annot=True)"]},{"cell_type":"markdown","metadata":{"id":"bKJ8uxlcUPwd"},"source":["## Tarefa de classificação de NLP\n","\n","Vamos passar para a tarefa real. Para tornar as coisas um pouco mais fáceis, iremos utilizar apenas avaliações de 1 ou 5 estrelas.\n","\n","**Crie um dataframe chamado yelp_class que contém as colunas do yelp dataframe, mas apenas para as avaliações de 1 ou 5 estrelas.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"MhhbL1xhUPwd"},"outputs":[],"source":["yelp_class = yelp[(yelp.stars==1) | (yelp.stars==5)]"]},{"cell_type":"markdown","metadata":{"id":"omQRJe9GUPwd"},"source":["**Crie dois objetos X e y. X será a coluna 'text' de yelp_class e y será a coluna 'stars' de yelp_class, suas características (features) e alvo/rótulos (target/labels), respectivamente**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"m3OJqUK4UPwd"},"outputs":[],"source":["X = yelp_class['text']\n","y = yelp_class['stars']"]},{"cell_type":"markdown","metadata":{"id":"wIn-MxB5UPwd"},"source":["**Importe CountVectorizer e crie um objeto CountVectorizer.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"KDMPbwDvUPwe"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer()"]},{"cell_type":"markdown","metadata":{"id":"p0F3CWttUPwe"},"source":["**Use o método fit_transform no objeto CountVectorizer e passe em X (coluna 'texto'). Salve este resultado substituindo X.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBCKreiPUPwe"},"outputs":[],"source":["X = cv.fit_transform(X)"]},{"cell_type":"markdown","metadata":{"id":"j25sKVs_UPwe"},"source":["## Divisão de teste/treinamento\n","\n","Vamos dividir nossos dados em dados de treinamento e teste.\n","\n","**Use train_test_split para dividir os dados em X_train, X_test, y_train, y_test. Use test_size=0.3 e random_state=101**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"d34AY-_-UPwe"},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"60SGyTVaUPwe"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)"]},{"cell_type":"markdown","metadata":{"id":"A1MI55CCUPwe"},"source":["## Treinando um Modelo\n","\n","**Importe MultinomialNB, crie uma instância do estimador e chame de nb **"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"DeaZ1BsbUPwf"},"outputs":[],"source":["from sklearn.naive_bayes import MultinomialNB\n","nb = MultinomialNB()"]},{"cell_type":"markdown","metadata":{"id":"dtkEdVw4UPwf"},"source":["**Agora ajuste nb usando os dados de treinamento.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5f3X1p2rUPwf"},"outputs":[],"source":["nb.fit(X_train,y_train)"]},{"cell_type":"markdown","metadata":{"id":"73CLY-cBUPwf"},"source":["## Previsões e avaliações\n","\n","**Use o método predict de nb para prever rótulos de X_test.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Ji9ftnxWUPwf"},"outputs":[],"source":["predictions = nb.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"AkE8q8AGUPwf"},"source":["**Crie uma matriz de confusão (confusion matrix) e um relatório de classificação (classification report) usando essas previsões e y_test**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Er0RVd4nUPwg"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MN05fvuaUPwg"},"outputs":[],"source":["print(confusion_matrix(y_test,predictions))\n","print('\\n')\n","print(classification_report(y_test,predictions))"]},{"cell_type":"markdown","metadata":{"id":"x4MOxnxyUPwg"},"source":["**Excelente! Vamos ver o que acontece se tentarmos incluir TF-IDF nesse processo usando um pipeline.**"]},{"cell_type":"markdown","metadata":{"id":"vzkt4xJtUPwg"},"source":["# Usando processamento de texto\n","\n","**Importar TfidfTransformer de sklearn.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"mYuUUrdhUPwg"},"outputs":[],"source":["from sklearn.feature_extraction.text import  TfidfTransformer"]},{"cell_type":"markdown","metadata":{"id":"QEuj3AE-UPwg"},"source":["** Importar Pipeline de sklearn.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"4-HRn5KGUPwg"},"outputs":[],"source":["from sklearn.pipeline import Pipeline"]},{"cell_type":"markdown","metadata":{"id":"jPjmqo0_UPwg"},"source":["**Agora crie um pipeline com os seguintes passos:CountVectorizer(), TfidfTransformer(),MultinomialNB()**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DNbXAyzUPwg"},"outputs":[],"source":["pipeline = Pipeline([\n","    ('bow', CountVectorizer()),  # strings para contagens inteiras de token\n","    ('tfidf', TfidfTransformer()),  # contagens inteiras para pontuações TF-IDF ponderadas\n","    ('classifier', MultinomialNB()),  # treine em vetores TF-IDF com classificador Naive Bayes\n","])"]},{"cell_type":"markdown","metadata":{"id":"0ZiL8aDYUPwh"},"source":["## Usando o pipeline\n","\n","**Hora de usar o pipeline! Lembre-se de que este pipeline já contém todas as etapas de pré-processamento, o que significa que precisaremos dividir novamente os dados originais (lembre-se de que substituímos X como a versão CountVectorized. O que precisamos é apenas o texto **"]},{"cell_type":"markdown","metadata":{"id":"XQKOFzVoUPwh"},"source":["### Divisão treino/teste\n","\n","**Refaça a divisão teste/treino no objeto yelp_class.**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"u4-t8zrGUPwh"},"outputs":[],"source":["X = yelp_class['text']\n","y = yelp_class['stars']\n","X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)"]},{"cell_type":"markdown","metadata":{"id":"dWC1ZJ-7UPwh"},"source":["**Agora ajuste o pipeline aos dados de treinamento. Lembre-se de que você não pode usar os mesmos dados de treinamento da última vez porque esses dados já foram vetorizados. Precisamos passar apenas o texto e os rótulos**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMUdtR1cUPwh"},"outputs":[],"source":["# May take some time\n","pipeline.fit(X_train,y_train)"]},{"cell_type":"markdown","metadata":{"id":"-6uU-TuTUPwh"},"source":["### Previsões e avaliação\n","\n","**Agora use o pipeline para prever a partir do X_test e criar um relatório de classificação e uma matriz de confusão. Você deve observar resultados estranhos.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qrf8QmvnUPwi"},"outputs":[],"source":["predictions = pipeline.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9gaSqJkUPwi"},"outputs":[],"source":["print(confusion_matrix(y_test,predictions))\n","print(classification_report(y_test,predictions))"]},{"cell_type":"markdown","metadata":{"id":"fuivJD6gUPwi"},"source":["Aparentemente o Tf-Idf piorou as coisas!"]},{"cell_type":"code","source":[],"metadata":{"id":"GROXXNW9gKuu"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"},"colab":{"provenance":[],"collapsed_sections":["XQKOFzVoUPwh","-6uU-TuTUPwh"]}},"nbformat":4,"nbformat_minor":0}